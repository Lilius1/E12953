# E12953

Social media shares
-	Lilius Schlenzig
-	Giuly Migliorini
-	Timo Vossebeld

Introduction
For the company that we are currently working for, we analyzed the communicationsâ€™ success. We have developed a tool to predict the number of shares on social media given the contents and the supposed publication time. Therefore we designed a machine learning solution. The machine learning solution is based on a collection of independent variables forming our dataset. In order to get the right solution, we coded in Python and started with the visualization of the dataset. We generated the training and test set and preprocessed the dataset in order to obtain the clean data for the tests we performed. We tested 3 different regressors by creating validation sets from the training sets to analyze the behavior with default hyperparameters. After that, the best architecture was selected while using the right metric, after which the performance of the test set could be computed. Finally, we selected only the most relevant subset of attributes and trained our best model to compare the final performances. 

Methods
When we finished the visualization of our dataset, we saw that we had too much raw data. In order to get clean data, we had to preprocess the dataset. The preprocessing was done on the independent variables. Therefore, we had to split the dataset into the independent variables (x) and the dependent variable (y). After that we had to drop the first column since this only labeled the rows and had no real data. We then generated a training and test set by splitting the data. We continued coding with the training set and only used the test set at the end to compute the performances. So continuing with the training set, encoding the categorical features with one-hot encoding was not needed, since this was already performed in the dataset. Therefore, we were able to immediately use standard scaling for the dataset to center the values around the mean with a unit standard deviation. After that, we looked at the accuracy for every independent variable of the dataset and determined if they were relevant or not. The variables with bad accuracy (i.e. irrelevant variables) were deleted and we continued with the rest of the dataset. For the independent variables with good accuracy we removed the outliers with the use of boxplots for every single variable. At first, we wanted to delete all the data points per variable that were outside the first and third quartile of the boxplot. However, when we did that there were only 145 rows left. Therefore, we decided to change the upper and lower bound to q3 and q97 instead of q25 and q75 so there would be enough data left to do the tests. We then replaced the outliers with null values such that we could drop them once all of them were identified. By changing the upper - and lower bound, we had a desired number of rows left on which we could continue to do experiments. These are described in the next section.  

Experimental Design
Once the training dataset consisted only of clean data, we started with the experiments. We did the experiments with the use of three different regression methods. We conducted the experiments with linear regression cross validation, logistic regression cross validation, and random forest cross validation. We decided to go with multiple linear regression since this was a nice means to establish the relationship between the number of shares as the dependent variable and the multiple independent variables, which were numerical (both numbers and binary variables). Besides that, Logistic regression is good to implement, interpret, very efficient to train, and It can interpret model coefficients as indicators of feature importance. Finally, we also used cross validation to measure the optimum performance on the random forest model we created. 
For all three different cross validations, we decided to use a quantity of five folds for all cross validations. We therefore rotated these folds in the training and validation sets. This provided us the ability to estimate the model performance on unseen data not used while training. In order to decide which model was best, we took the mean of the cross validation scores with this particular number of folds. The regressor that got the lowest mean score pointed out to be the best option.

Results
Eventually, after performing the different cross validations, we had to find out which model performed best compared to the other ones. We measured this with the use of accuracies of the different regressors. It turned out that two out of three codes for the accuracy for the models were negative, which is wrong in any case. From our codes, the accuracy of our logistic regression turned out to be: -0.03238126541711184 and the accuracy of the random forest regressor is: -0.022672206501842096. The model with our best (and possibly the only correct) accuracy is therefore the one from the linear regression with an accuracy of: 0.013624695943616705. Since this value is still also very low positive, the model is not able to make a good estimation on the number of shares as a result of the generation of big errors in most of the data.

Conclusions
As we could already see in the first step of the data visualization, there was a very small correlation between the independent variables and the dependent variable; number of shares. This could explain that the accuracy from our models was really low. During the project, we put in a lot of hours to prepare the data in certain ways to make the model fit to the expectations and therefore try to increase our accuracy. However, as it turned out, we have not been able to create a good model since it was very hard for us to estimate the number of shares with a high accuracy given these independent variables.
Therefore, we have not been able to give a clear prediction on the number of social media shares given all these multiple independent variables. Since we did not succeed in this, we are also not really sure if our different cross validations with as output the means made sense for the final purpose to predict the shares. Therefore, taking everything into consideration for future work, we could better look for proper means to prepare the data. If we succeed, we can use the right metric to create a good model in order to make a clear and proper prediction for the number of social media shares given these independent variables. 
